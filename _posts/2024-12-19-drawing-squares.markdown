---
layout: post
title:  "Drawing Squares"
date:   2024-12-18 12:00:00 -0400
categories: jekyll update
---

<script type="text/javascript" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<link rel="stylesheet" href="/assets/css/styles.css">

![Long Exposure Laser Square Drawn by Robot](/assets/images/laser_square.jpeg)

<hr style = "margin-top: 4rem">
<br /><br />

## ðŸŒ“ : Progress

The robot arm is moving! The photo above is ~40 second exposure of a laser drawing made by the robot arm.

To create the double-square, I sent cartesian coordinate commands over a ROS topic, which were converted into desired shoulder and elbow joint velocities via a custom [ROS2 control controller][3]. The transformation from cartesian-space commands to joint-space commands was done using differential inverse kinematics with the help of the Drake [CalcJacobianTranslationalVelocity][1] function and the Eigen [pseudoinverse][2] function.

Because both the ODrive shoulder joint and NEMA17 stepper elbow joint use position control, these resulting joint-velocity commands are then integrated to give joint-position commands. These commands are sent from ROS2 (running on a RPi5) to the ODrive S1 and Arduino via CAN bus. These two devices also send their motor's position and velocity back to ROS2 over CAN, which is important for Drake to use to calculate a new Jacobian matrix.

One of the most obvious problems, which can be seen via the spiraling laser lines, is that the shoulder joint vibrates at low speeds. I'm going to spend some time properly tuning the PI parameters for the ODrive, and maybe enabling anticogging to hopefully improve this.

The other problem is that the sides of the square are not really straight. I feel like I can even see this slightly concave path taken by the end effector in RViz (see the video below). I'm not too sure whats causing this yet... probably need to think of a way to better keep the ODrive and stepper in sync with each other.

<br /><br />

<iframe width="840" height="473" src="https://www.youtube.com/embed/2VtBVIsuxbI" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<hr style = "margin-top: 4rem">
<br /><br />

## ðŸŒ—ï¸Ž : Possible Next Steps

- try current/acceleration/velocity control
- anticogging and better PI tuning for ODrive to reduce shoulder actuator jitter
- abstracted solution to transmissions that Drake accepts (Drake multibody plants do not accept transmissions in URDFs)
- motion planning and trajectory optimization
- tracing photos from paths generated by canny edge detection
- calculate ping pong ball trajectories with stereo vision (is two OpenCV SimpleBlob streams to get stereo disparity enough? RAFTStereo?)
- adding position and velocity limits. hardware side... (on the arduino and S1), or software side (in ROS2)? both?



<!-- links -->
[1]: https://drake.mit.edu/doxygen_cxx/classdrake_1_1multibody_1_1_multibody_plant.html#ae2516569f5a2cc27e76ee0cc8b728746
[2]: http://eigen.tuxfamily.org/dox/classEigen_1_1CompleteOrthogonalDecomposition.html#ab5e8b3f2c7b602772e1f1d7ce63d446e
[3]: https://control.ros.org/jazzy/doc/ros2_controllers/doc/writing_new_controller.html